{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windy Gridworld mit Sarsa und erweiterten Aktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe ist die Progammierübung 2, siehe Aufgabenblatt in moodle. Grundlage ist das bereit gestellte Framework sowie das windy Gridworld aus der Vorlesung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anpassen der Systempath variable für das Importieren von gym\n",
    "import sys\n",
    "sys.path.append('/opt/anaconda3/envs/rl_course/lib/python3.10/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn folgende Imports funktionieren, ist ihre Python Umgebung korrekt aufgesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importieren der mitgelieferten Python Module, diese müssen im gleichen Verzeichnis wie das Notebook liegen!\n",
    "import windy\n",
    "from sarsa import sarsa, run_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisieren der Umgebung\n",
    "env = gym.make('WindyGridworld-v0')\n",
    "q, policy, history = sarsa(env, 500, eps0=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotten der Episoden über die Zeitschritte. Zur korrekten Anzeige müssen im Ausgabearray history jeweils die benötigten Zeitschritte pro Episode hinterlegt sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Time steps\"); plt.xlim(0, 8_000)\n",
    "plt.ylabel(\"Episodes\"); plt.ylim(0, 170)\n",
    "timesteps = np.cumsum([0] + history)\n",
    "plt.plot(timesteps, np.arange(len(timesteps)), color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies ist eine Hilfsvisualisierungsfunktion um die Bewertungsfunktion mit entsprechenden maximalen q-values als Pfeilen anzuzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "def plot_results(env, q, policy):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    ax.set_title(\"Optimal Value Function and Policy\")\n",
    "    \n",
    "    q = np.copy(q)\n",
    "    unvisited = np.where(q == 0)\n",
    "    q[unvisited] = -np.inf\n",
    "    v = np.max(q, axis=1).reshape(env.observation_space.nvec)\n",
    "    ax.imshow(v.T, origin='lower')\n",
    "\n",
    "    a_stars = np.argmax(policy, axis=1)\n",
    "    arrows = np.array([env.actions[a] for a in a_stars])\n",
    "    arrows[unvisited[0], :] = 0\n",
    "    arrows = arrows.reshape([*env.observation_space.nvec, 2])\n",
    "    xr = np.arange(env.observation_space.nvec[0])\n",
    "    yr = np.arange(env.observation_space.nvec[1])\n",
    "    ax.quiver(xr, yr, arrows[:, :, 0].T, arrows[:, :, 1].T, pivot='mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(env, q, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = run_episode(env, policy, render=True)\n",
    "print(f\"Episode length = {len(rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach Anpassen der Umgebung um die king's Aktionen mit zu berücksichtigen können Sie hier ihre Implementierung testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('WindyGridworld-v0', king=True)\n",
    "q, policy, _ = sarsa(env, 500, eps0=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(env, q, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = run_episode(env, policy, render=True)\n",
    "print(f\"Episode length = {len(rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach Berücksichtigung der zusätzlichen Stop Aktion können Sie hier ihre Implementierung testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('WindyGridworld-v0', king=True, stop=True)\n",
    "q, policy, _ = sarsa(env, 500, eps0=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(env, q, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = run_episode(env, policy, render=True)\n",
    "print(f\"Episode length = {len(rewards)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
